{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic challenge with SageMaker - XGBoost as a framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook in in the series of learning SageMaker with Titanic challenge. The original challenge is defined at https://www.kaggle.com/c/titanic/data. In this notebook I experiment using SageMaker XGBoost as a framework. In particular, I use a customized traning script to make it do the cross validation. The whole training process is performed at local.\n",
    "\n",
    "Requirements:\n",
    "- Docker installed at local.\n",
    "- Developing environment with Python and necessary libraries/packages.\n",
    "- Due to some errors when sagemaker xgboost handles csv file at local mode, data is uploaded into S3 instead. Then we need a S3 bucket and a role with the access to S3.\n",
    "\n",
    "This piece of code uses SageMaker 2.18.0 and XGBoost.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define bucket name and prefix\n",
    "bucket = '<your-bucket-name>' \n",
    "prefix = '<your-bucket-prefix>' # for example, sagemaker/titanic\n",
    "\n",
    "# Define IAM role and sagemaker client\n",
    "boto_session = boto3.Session()\n",
    "session = sagemaker.Session(boto_session=boto_session)\n",
    "role = '<your-role-arn>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the local data path\n",
    "train_data_file = './data/processed/exp-raw/train.csv'\n",
    "validation_data_file = './data/processed/exp-raw/validation.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load into one\n",
    "train_df = pd.read_csv(train_data_file,header=None)\n",
    "validation_df = pd.read_csv(validation_data_file,header=None)\n",
    "\n",
    "merged_df = pd.concat([train_df,validation_df])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 11) (179, 11) (891, 11)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape, validation_df.shape,merged_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('./data/processed/train.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_train_uri = session.upload_data(path='./data/processed/train.csv', bucket=bucket, key_prefix='/'.join((prefix, 'train')))\n",
    "# s3_validate_uri = session.upload_data(path='data/processed/exp-raw/validation.csv', bucket=bucket, key_prefix='/'.join((prefix, 'validation')))\n",
    "# s3_test_uri = session.upload_data(path='data/processed/exp-raw/test.csv', bucket=bucket, key_prefix='/'.join((prefix, 'test')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input points for xgboost\n",
    "input_train = sagemaker.inputs.TrainingInput(s3_data=s3_train_uri, content_type='csv')\n",
    "# input_validation = sagemaker.inputs.TrainingInput(s3_data=s3_validate_uri, content_type='csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to write a training script for our XGBoost in which:\n",
    "- Define parameters will be passed to XGBoost\n",
    "- Get the input data and convert it to DMatrix to work with XGBoost, using help function from XGBoost SageMaker\n",
    "- Call the .cv() function of XGBoost to do cross validation\n",
    "- Write the result to the output directory, data in this directory will be uploaded into S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "\n",
    "from sagemaker_containers import entry_point\n",
    "from sagemaker_xgboost_container.data_utils import get_dmatrix\n",
    "from sagemaker_xgboost_container import distributed\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import boto3\n",
    "\n",
    "def _xgb_train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        evals,\n",
    "        num_boost_round,\n",
    "        num_fold,\n",
    "        seed,\n",
    "        model_dir,\n",
    "        output_data_dir,\n",
    "        is_master,\n",
    "        early_stopping_round):\n",
    "    \"\"\"Run xgb cross validation on arguments given with rabit initialized.\n",
    "\n",
    "    This is our rabit execution function.\n",
    "\n",
    "    :param args_dict: Argument dictionary used to run xgb.cv().\n",
    "    :param is_master: True if current node is master host in distributed training, or is running single node training job. Note that rabit_run will include this argument.\n",
    "    \"\"\"\n",
    "\n",
    "    cvresult = xgb.cv(\n",
    "        params=params,\n",
    "        dtrain=dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        nfold=num_fold,\n",
    "        metrics=['auc'],\n",
    "        early_stopping_rounds=early_stopping_round,\n",
    "        stratified=True,\n",
    "        seed=seed)\n",
    "\n",
    "    if is_master:\n",
    "        model_location = output_data_dir + '/cv-result'\n",
    "        pkl.dump(cvresult, open(model_location, 'wb'))\n",
    "        logging.info(\"Stored cv result at {}\".format(model_location))\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # cross validation params\n",
    "    parser.add_argument('--k_fold', type=int)\n",
    "\n",
    "    # Hyperparameters are described here. In this simple example we are just\n",
    "    # including one hyperparameter.\n",
    "    parser.add_argument('--max_depth', type=int)\n",
    "    parser.add_argument('--eta', type=float)\n",
    "    parser.add_argument('--gamma', type=int)\n",
    "    parser.add_argument('--min_child_weight', type=int)\n",
    "    parser.add_argument('--subsample', type=float)\n",
    "    parser.add_argument('--verbose', type=int)\n",
    "    parser.add_argument('--objective', type=str)\n",
    "    parser.add_argument('--num_round', type=int)\n",
    "    parser.add_argument('--early_stopping_round', type=int)\n",
    "    parser.add_argument('--eval_metric', type=str)\n",
    "    parser.add_argument('--num_fold', type=int)\n",
    "    parser.add_argument('--seed', type=int)\n",
    "\n",
    "    # Sagemaker specific arguments. Defaults are set in the environment\n",
    "    # variables.\n",
    "    parser.add_argument('--output_data_dir', type=str,\n",
    "                        default=os.environ['SM_OUTPUT_DATA_DIR'])\n",
    "    parser.add_argument('--model_dir', type=str,\n",
    "                        default=os.environ['SM_MODEL_DIR'])\n",
    "    parser.add_argument('--train', type=str,\n",
    "                        default=os.environ['SM_CHANNEL_TRAIN'])\n",
    "    parser.add_argument('--sm_hosts', type=str, default=os.environ['SM_HOSTS'])\n",
    "    parser.add_argument('--sm_current_host', type=str,\n",
    "                        default=os.environ['SM_CURRENT_HOST'])\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    # Get SageMaker host information from runtime environment variables\n",
    "    sm_hosts = json.loads(os.environ['SM_HOSTS'])\n",
    "    sm_current_host = args.sm_current_host\n",
    "\n",
    "    dtrain = get_dmatrix(args.train, 'csv')\n",
    "    watchlist = [(dtrain, 'train')]\n",
    "\n",
    "    train_hp = {\n",
    "        'max_depth': args.max_depth,\n",
    "        'eta': args.eta,\n",
    "        'gamma': args.gamma,\n",
    "        'min_child_weight': args.min_child_weight,\n",
    "        'subsample': args.subsample,\n",
    "        'verbose': args.verbose,\n",
    "        'objective': args.objective,\n",
    "        'eval_metric': args.eval_metric\n",
    "    }\n",
    "\n",
    "    xgb_train_args = dict(\n",
    "        params=train_hp,\n",
    "        dtrain=dtrain,\n",
    "        evals=watchlist,\n",
    "        num_boost_round=args.num_round,\n",
    "        num_fold=args.num_fold,\n",
    "        seed=args.seed,\n",
    "        model_dir=args.model_dir,\n",
    "        early_stopping_round=args.early_stopping_round,\n",
    "        output_data_dir=args.output_data_dir)\n",
    "\n",
    "    if len(sm_hosts) > 1:\n",
    "        # Wait until all hosts are able to find each other\n",
    "        entry_point._wait_hostname_resolution()\n",
    "\n",
    "        # Execute training function after initializing rabit.\n",
    "        distributed.rabit_run(\n",
    "            exec_fun=_xgb_train,\n",
    "            args=xgb_train_args,\n",
    "            include_in_training=(dtrain is not None),\n",
    "            hosts=sm_hosts,\n",
    "            current_host=sm_current_host,\n",
    "            update_rabit_args=True\n",
    "        )\n",
    "    else:\n",
    "        # If single node training, call training method directly.\n",
    "        if dtrain:\n",
    "            xgb_train_args['is_master'] = True\n",
    "            _xgb_train(**xgb_train_args)\n",
    "        else:\n",
    "            raise ValueError(\"Training channel must have data to train model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "        \"eval_metric\": \"auc\",\n",
    "        \"early_stopping_round\":\"50\",\n",
    "        \"objective\":\"binary:logistic\",\n",
    "        \"num_round\":\"50\",\n",
    "        \"num_fold\":\"5\",\n",
    "        \"seed\":\"1819\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the estimator and hyperparams\n",
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "xgb = XGBoost(\n",
    "    entry_point='scripts/entry.py',\n",
    "    framework_version='1.0-1',\n",
    "    hyperparameters=params,\n",
    "    role=role, \n",
    "    instance_count=1, \n",
    "    instance_type='local',\n",
    "    output_path='s3://{}/{}/output'.format(bucket, prefix)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "xgb.fit({'train': input_train})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It took 14.4s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03. Verify the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# job name is created auto if we don't specify one when we call .fit()\n",
    "job_name='sagemaker-xgboost-2020-12-16-09-52-02-780'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.client('s3').download_file(bucket, '{}/output/{}/output.tar.gz'.format(prefix,job_name), 'output/cross_val_result.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xf  output/cross_val_result.tar.gz -C output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 8\r\n",
      "drwxrwxrwx 1 jiji jiji    0 déc.   8 16:15 cross_val_result1\r\n",
      "-rwxrwxrwx 1 jiji jiji  789 déc.   8 17:33 cross_val_result2.tar.gz\r\n",
      "-rwxrwxrwx 1 jiji jiji 2449 déc.  16 10:52 cross_val_result.tar.gz\r\n",
      "drwxrwxrwx 1 jiji jiji  152 déc.  16 10:52 data\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl \n",
    "\n",
    "with open('output/data/cv-result', 'rb') as pickle_file:\n",
    "    cv_result = pkl.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-auc-mean</th>\n",
       "      <th>train-auc-std</th>\n",
       "      <th>test-auc-mean</th>\n",
       "      <th>test-auc-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.891615</td>\n",
       "      <td>0.007249</td>\n",
       "      <td>0.839727</td>\n",
       "      <td>0.033336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.914508</td>\n",
       "      <td>0.003851</td>\n",
       "      <td>0.846446</td>\n",
       "      <td>0.031690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.929480</td>\n",
       "      <td>0.002587</td>\n",
       "      <td>0.862434</td>\n",
       "      <td>0.028660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.936343</td>\n",
       "      <td>0.001959</td>\n",
       "      <td>0.861230</td>\n",
       "      <td>0.025279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.944799</td>\n",
       "      <td>0.006118</td>\n",
       "      <td>0.857478</td>\n",
       "      <td>0.028622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.952957</td>\n",
       "      <td>0.005311</td>\n",
       "      <td>0.862400</td>\n",
       "      <td>0.023567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.958371</td>\n",
       "      <td>0.004624</td>\n",
       "      <td>0.860739</td>\n",
       "      <td>0.025974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.961795</td>\n",
       "      <td>0.004114</td>\n",
       "      <td>0.860780</td>\n",
       "      <td>0.024435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.965844</td>\n",
       "      <td>0.004601</td>\n",
       "      <td>0.858598</td>\n",
       "      <td>0.025320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.969108</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>0.859689</td>\n",
       "      <td>0.026967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.972945</td>\n",
       "      <td>0.003621</td>\n",
       "      <td>0.858886</td>\n",
       "      <td>0.029094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.975208</td>\n",
       "      <td>0.004624</td>\n",
       "      <td>0.859456</td>\n",
       "      <td>0.028340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.978173</td>\n",
       "      <td>0.003976</td>\n",
       "      <td>0.858515</td>\n",
       "      <td>0.027239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.980180</td>\n",
       "      <td>0.004522</td>\n",
       "      <td>0.856822</td>\n",
       "      <td>0.030457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.981594</td>\n",
       "      <td>0.004483</td>\n",
       "      <td>0.855894</td>\n",
       "      <td>0.029944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.983474</td>\n",
       "      <td>0.004078</td>\n",
       "      <td>0.856724</td>\n",
       "      <td>0.031148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.985321</td>\n",
       "      <td>0.004276</td>\n",
       "      <td>0.855653</td>\n",
       "      <td>0.032481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.987326</td>\n",
       "      <td>0.004007</td>\n",
       "      <td>0.855727</td>\n",
       "      <td>0.032807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.988650</td>\n",
       "      <td>0.003455</td>\n",
       "      <td>0.856163</td>\n",
       "      <td>0.033155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.989424</td>\n",
       "      <td>0.003418</td>\n",
       "      <td>0.853981</td>\n",
       "      <td>0.032441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.990693</td>\n",
       "      <td>0.002916</td>\n",
       "      <td>0.853456</td>\n",
       "      <td>0.033392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.991947</td>\n",
       "      <td>0.002499</td>\n",
       "      <td>0.852488</td>\n",
       "      <td>0.030622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.992775</td>\n",
       "      <td>0.002221</td>\n",
       "      <td>0.850778</td>\n",
       "      <td>0.029734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.993482</td>\n",
       "      <td>0.001940</td>\n",
       "      <td>0.849689</td>\n",
       "      <td>0.030249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.993984</td>\n",
       "      <td>0.001704</td>\n",
       "      <td>0.848993</td>\n",
       "      <td>0.029800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.994692</td>\n",
       "      <td>0.001448</td>\n",
       "      <td>0.848062</td>\n",
       "      <td>0.029033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.995383</td>\n",
       "      <td>0.001151</td>\n",
       "      <td>0.847020</td>\n",
       "      <td>0.029803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.995992</td>\n",
       "      <td>0.000969</td>\n",
       "      <td>0.846564</td>\n",
       "      <td>0.028737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.996260</td>\n",
       "      <td>0.000996</td>\n",
       "      <td>0.844595</td>\n",
       "      <td>0.028327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.996596</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>0.844217</td>\n",
       "      <td>0.027603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.996852</td>\n",
       "      <td>0.001043</td>\n",
       "      <td>0.844352</td>\n",
       "      <td>0.027343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.997218</td>\n",
       "      <td>0.000893</td>\n",
       "      <td>0.844724</td>\n",
       "      <td>0.027444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.997436</td>\n",
       "      <td>0.000812</td>\n",
       "      <td>0.843477</td>\n",
       "      <td>0.027612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.997841</td>\n",
       "      <td>0.000622</td>\n",
       "      <td>0.843741</td>\n",
       "      <td>0.027171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.998013</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>0.842786</td>\n",
       "      <td>0.028110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.998202</td>\n",
       "      <td>0.000570</td>\n",
       "      <td>0.842440</td>\n",
       "      <td>0.027491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.998374</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>0.842528</td>\n",
       "      <td>0.028721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.998522</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>0.842944</td>\n",
       "      <td>0.026932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.998689</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>0.843027</td>\n",
       "      <td>0.027757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.998918</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.842059</td>\n",
       "      <td>0.027097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.999048</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.842860</td>\n",
       "      <td>0.027256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.999203</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.843870</td>\n",
       "      <td>0.027593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.999276</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.843547</td>\n",
       "      <td>0.026694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.999334</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.842992</td>\n",
       "      <td>0.027013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.999493</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>0.841978</td>\n",
       "      <td>0.027428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.999569</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.842893</td>\n",
       "      <td>0.027845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.999637</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.842305</td>\n",
       "      <td>0.027228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.999699</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.841451</td>\n",
       "      <td>0.028936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.999740</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.840521</td>\n",
       "      <td>0.029325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.999775</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.839810</td>\n",
       "      <td>0.030496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train-auc-mean  train-auc-std  test-auc-mean  test-auc-std\n",
       "0         0.891615       0.007249       0.839727      0.033336\n",
       "1         0.914508       0.003851       0.846446      0.031690\n",
       "2         0.929480       0.002587       0.862434      0.028660\n",
       "3         0.936343       0.001959       0.861230      0.025279\n",
       "4         0.944799       0.006118       0.857478      0.028622\n",
       "5         0.952957       0.005311       0.862400      0.023567\n",
       "6         0.958371       0.004624       0.860739      0.025974\n",
       "7         0.961795       0.004114       0.860780      0.024435\n",
       "8         0.965844       0.004601       0.858598      0.025320\n",
       "9         0.969108       0.003785       0.859689      0.026967\n",
       "10        0.972945       0.003621       0.858886      0.029094\n",
       "11        0.975208       0.004624       0.859456      0.028340\n",
       "12        0.978173       0.003976       0.858515      0.027239\n",
       "13        0.980180       0.004522       0.856822      0.030457\n",
       "14        0.981594       0.004483       0.855894      0.029944\n",
       "15        0.983474       0.004078       0.856724      0.031148\n",
       "16        0.985321       0.004276       0.855653      0.032481\n",
       "17        0.987326       0.004007       0.855727      0.032807\n",
       "18        0.988650       0.003455       0.856163      0.033155\n",
       "19        0.989424       0.003418       0.853981      0.032441\n",
       "20        0.990693       0.002916       0.853456      0.033392\n",
       "21        0.991947       0.002499       0.852488      0.030622\n",
       "22        0.992775       0.002221       0.850778      0.029734\n",
       "23        0.993482       0.001940       0.849689      0.030249\n",
       "24        0.993984       0.001704       0.848993      0.029800\n",
       "25        0.994692       0.001448       0.848062      0.029033\n",
       "26        0.995383       0.001151       0.847020      0.029803\n",
       "27        0.995992       0.000969       0.846564      0.028737\n",
       "28        0.996260       0.000996       0.844595      0.028327\n",
       "29        0.996596       0.001002       0.844217      0.027603\n",
       "30        0.996852       0.001043       0.844352      0.027343\n",
       "31        0.997218       0.000893       0.844724      0.027444\n",
       "32        0.997436       0.000812       0.843477      0.027612\n",
       "33        0.997841       0.000622       0.843741      0.027171\n",
       "34        0.998013       0.000666       0.842786      0.028110\n",
       "35        0.998202       0.000570       0.842440      0.027491\n",
       "36        0.998374       0.000588       0.842528      0.028721\n",
       "37        0.998522       0.000574       0.842944      0.026932\n",
       "38        0.998689       0.000597       0.843027      0.027757\n",
       "39        0.998918       0.000438       0.842059      0.027097\n",
       "40        0.999048       0.000376       0.842860      0.027256\n",
       "41        0.999203       0.000290       0.843870      0.027593\n",
       "42        0.999276       0.000273       0.843547      0.026694\n",
       "43        0.999334       0.000238       0.842992      0.027013\n",
       "44        0.999493       0.000186       0.841978      0.027428\n",
       "45        0.999569       0.000155       0.842893      0.027845\n",
       "46        0.999637       0.000137       0.842305      0.027228\n",
       "47        0.999699       0.000129       0.841451      0.028936\n",
       "48        0.999740       0.000116       0.840521      0.029325\n",
       "49        0.999775       0.000099       0.839810      0.030496"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result shows the score statistic for each iteration. For example here I put the max round as 50 and fold number as 5, therefore the model is trained 5 times with difference train/validation sets. Each training uses 50 decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
